{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxI6EKFDteS5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV6xd0F5tpJZ"
      },
      "source": [
        "## Supervised Learning- Classification\n",
        "\n",
        "- Supervised Pneumonia Classification on Chest X-Ray Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUl6Gb82tzrX"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/MTL_on_Chest_X_Ray_Images/archive.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLcHqzBQt4Iu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import argparse\n",
        "%matplotlib inline\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Input, Flatten, Dropout, BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras import backend as K\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Input, concatenate\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfiHlOflt4LY"
      },
      "outputs": [],
      "source": [
        "# Path to the directory containing the images\n",
        "train_dir_path =\"chest_xray/chest_xray/train\"\n",
        "test_dir_path= \"chest_xray/chest_xray/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BywPID6t4OJ"
      },
      "outputs": [],
      "source": [
        "# Get few samples for both the classes\n",
        "normal_cases_dir = os.path.join(train_dir_path,'NORMAL')\n",
        "pneumonia_cases_dir = os.path.join(train_dir_path,'PNEUMONIA')\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = glob(normal_cases_dir + '/*.jpeg')\n",
        "pneumonia_cases = glob(pneumonia_cases_dir + '/*.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_CD5s0Ct4TD"
      },
      "outputs": [],
      "source": [
        "print(f\"Total number of image for normal cases : {len(normal_cases)}\\n\\\n",
        "Total number of image for pneumonia cases : {len(pneumonia_cases)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFLUl16xt4Vx"
      },
      "outputs": [],
      "source": [
        "samples=[]\n",
        "for i in range(5):\n",
        "    samples.append(normal_cases[i])\n",
        "for i in range(5):\n",
        "    samples.append(pneumonia_cases[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVJ4lIYVt4Yb"
      },
      "outputs": [],
      "source": [
        "# Plot the data\n",
        "f, ax = plt.subplots(2,5, figsize=(40,15))\n",
        "for i in range(10):\n",
        "    img = imread(samples[i])\n",
        "    ax[i//5, i%5].imshow(img, cmap='gray')\n",
        "    if i<5:\n",
        "        ax[i//5, i%5].set_title(\"Normal\")\n",
        "    else:\n",
        "        ax[i//5, i%5].set_title(\"Pneumonia\")\n",
        "    ax[i//5, i%5].axis('off')\n",
        "    ax[i//5, i%5].set_aspect('auto')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsC0lhp1t4ao"
      },
      "outputs": [],
      "source": [
        "# Data generation objects\n",
        "train_datagen = ImageDataGenerator(zoom_range=0.1,\n",
        "                                   horizontal_flip = True,\n",
        "                                   fill_mode = 'constant',\n",
        "                                   validation_split=0.1,\n",
        "                                   preprocessing_function = preprocess_input)\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HONONcBzt4fK"
      },
      "outputs": [],
      "source": [
        "image_size = 224\n",
        "batch_size = 16\n",
        "\n",
        "# This is fed to the network in the specified batch sizes and image dimensions\n",
        "train_gen = train_datagen.flow_from_directory(train_dir_path,\n",
        "                                              target_size=(image_size, image_size),\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='binary',\n",
        "                                              shuffle=True,\n",
        "                                              subset='training')\n",
        "\n",
        "val_gen = train_datagen.flow_from_directory(train_dir_path, # same directory as training data\n",
        "                                                  target_size=(image_size, image_size),\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  shuffle = True,\n",
        "                                                  class_mode='binary',\n",
        "                                                  subset='validation')\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(test_dir_path,\n",
        "                                                target_size=(image_size, image_size),\n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='binary',\n",
        "                                                shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BtEZ2Lht4hg"
      },
      "outputs": [],
      "source": [
        "train_labels=[]\n",
        "\n",
        "for img_path in normal_cases:\n",
        "    train_labels.append(0)\n",
        "\n",
        "for img_path in pneumonia_cases:\n",
        "    train_labels.append(1)\n",
        "\n",
        "#convert label list to numpy array\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "#Compute class weights for each class\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',classes=np.unique(train_labels),y=train_labels)\n",
        "print(class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLwWxPuet4j7"
      },
      "outputs": [],
      "source": [
        "# create the base pre-trained model\n",
        "base_model = DenseNet121(weights='imagenet',include_top=False)\n",
        "x = base_model.output\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x= GlobalAveragePooling2D()(x)\n",
        "\n",
        "# dropout layer\n",
        "x= Dropout(0.2)(x)\n",
        "\n",
        "# add a logistic layers\n",
        "prediction = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model= Model(inputs=base_model.inputs, outputs=prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucqvEo4Bt4pp"
      },
      "outputs": [],
      "source": [
        "#Follow ChexNeXt Paper\n",
        "base_learning_rate = 0.0001\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=Adam(learning_rate= base_learning_rate),loss=\"binary_crossentropy\",metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1PpgHXyt4sx"
      },
      "outputs": [],
      "source": [
        "# epochs\n",
        "initial_epochs = 20\n",
        "\n",
        "# Callbacks\n",
        "#Save best model\n",
        "ckpt_filename= \"/content/drive/MyDrive/dn121_class_weights_pretrained.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=ckpt_filename, save_best_only=True, save_weights_only=True, verbose = 1)\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, mode='min', verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_V1ZIk3t4va"
      },
      "outputs": [],
      "source": [
        "# fitting the model\n",
        "history= model.fit(train_gen,\n",
        "                  epochs=initial_epochs,\n",
        "                  validation_data= val_gen,\n",
        "                  callbacks=[checkpoint, early_stop, lr_reduce],\n",
        "                  class_weight = {0: class_weights[0], 1: class_weights[1]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZrHnDSut4yV"
      },
      "outputs": [],
      "source": [
        "acc=  history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(acc,label='Training Accuracy')\n",
        "plt.plot(val_acc, label=\"validation accuracy\")\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([min(plt.ylim()),2])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJi3s47rt41J"
      },
      "outputs": [],
      "source": [
        "#Load the best model during initial training\n",
        "model.load_weights(ckpt_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP-4q_U8t44B"
      },
      "outputs": [],
      "source": [
        "# Finetuning - Unfreeze the last layers of the model\n",
        "base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD0ciWIwt46p"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "model.compile(optimizer= Adam(learning_rate=base_learning_rate/10), loss= \"binary_crossentropy\", metrics = ['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "final_ckpt_filename= \"/content/drive/MyDrive/dn121_class_weights_pretrained.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=final_ckpt_filename, save_best_only=True, save_weights_only=True, verbose = 1)\n",
        "\n",
        "checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZfqFFKjt49i"
      },
      "outputs": [],
      "source": [
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, mode='min', verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nla4x0fWt5AQ"
      },
      "outputs": [],
      "source": [
        "fine_tune_epochs = 20\n",
        "\n",
        "# Fitting the model\n",
        "history_unfreeze = model.fit(train_gen,\n",
        "                    epochs= fine_tune_epochs,\n",
        "                    validation_data=val_gen,\n",
        "                    callbacks=[checkpoint, early_stop, lr_reduce],\n",
        "                    class_weight = {0: class_weights[0], 1: class_weights[1]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxDuC1K1t5DC"
      },
      "outputs": [],
      "source": [
        "acc = history_unfreeze.history['accuracy']\n",
        "val_acc = history_unfreeze.history['val_accuracy']\n",
        "\n",
        "loss = history_unfreeze.history['loss']\n",
        "val_loss = history_unfreeze.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy after unfreezing all layers')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss after unfreezing all layers')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmxxEY_ot5F0"
      },
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "model.load_weights(final_ckpt_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWxxuA0nt5Ib"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-8lDm0Vt5LM"
      },
      "outputs": [],
      "source": [
        "#Evaluate on the test data\n",
        "test_loss, test_score = model.evaluate(test_gen)\n",
        "print(\"Loss on test set: \", test_loss)\n",
        "print(\"Accuracy on test set: \", test_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn5vJ51-t5N9"
      },
      "outputs": [],
      "source": [
        "def fn_preprocess_images(data_directory, image_size):\n",
        "    normal_dir = os.path.join(data_directory, 'NORMAL')\n",
        "    pneumonia_dir = os.path.join(data_directory, 'PNEUMONIA')\n",
        "\n",
        "     # Get the list of all the images\n",
        "    normal_cases = glob(normal_dir + '/*.jpeg')\n",
        "    pneumonia_cases = glob(pneumonia_dir + '/*.jpeg')\n",
        "\n",
        "    #Store all images and labels\n",
        "    image_data_list = []\n",
        "    labels = []\n",
        "\n",
        "    for img_path in normal_cases:\n",
        "        img = tf.keras.utils.load_img(img_path, target_size=(image_size, image_size))\n",
        "        x = tf.keras.utils.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        #print('Input image shape:', x.shape)\n",
        "        image_data_list.append(x)\n",
        "        labels.append(0)\n",
        "\n",
        "    for img_path in pneumonia_cases:\n",
        "        img = tf.keras.utils.load_img(img_path, target_size=(image_size, image_size))\n",
        "        x = tf.keras.utils.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        x = preprocess_input(x)\n",
        "        #print('Input image shape:', x.shape)\n",
        "        image_data_list.append(x)\n",
        "        labels.append(1)\n",
        "\n",
        "  # Convert the images to tensor shape (n_images, h, w, channel)\n",
        "    img_data = np.array(image_data_list)\n",
        "    img_data=np.rollaxis(img_data,1,0)\n",
        "    img_data=img_data[0]\n",
        "    print(\"Final data shape: \"+str(img_data.shape))\n",
        "\n",
        "    #convert label list to numpy array\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return img_data,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0Pp6747t5Qx"
      },
      "outputs": [],
      "source": [
        "test_data, test_labels  = fn_preprocess_images(test_dir_path, image_size = 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmifBwX8t5Tz"
      },
      "outputs": [],
      "source": [
        "# Predict on test data\n",
        "preds = model.predict(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDcQ-Uhpt5Wz"
      },
      "outputs": [],
      "source": [
        "# Classification report\n",
        "from sklearn.metrics import accuracy_score,classification_report, roc_curve, confusion_matrix\n",
        "\n",
        "acc = accuracy_score(test_labels, np.round(preds))*100\n",
        "print(\"Test data accuracy : \"+str(acc))\n",
        "print(\"Classification report\")\n",
        "print(classification_report(test_labels,np.round(preds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX27XirEt5Z3"
      },
      "outputs": [],
      "source": [
        "# Plot the confusion matrix\n",
        "conf_matrix = confusion_matrix(test_labels, np.round(preds))\n",
        "plt.figure(figsize=(12.8,6))\n",
        "sns.heatmap(conf_matrix,\n",
        "            annot=True,\n",
        "            xticklabels=['Bacteria Pneumonia', 'Virus Pneumonia'],\n",
        "            yticklabels=['Bacteria Pneumonia', 'Virus Pneumonia'],\n",
        "            cmap=\"Blues\",\n",
        "            fmt='g')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Confusion matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x04MyjnDt5cv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "y_preds = preds.ravel()\n",
        "model_fpr, model_tpr, model_threshold = roc_curve(test_labels, y_preds)\n",
        "model_auc = auc(model_fpr, model_tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLUcZZU-t5fn"
      },
      "outputs": [],
      "source": [
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(model_fpr, model_tpr, label='AUC Score(area = {:.3f})'.format(model_auc))\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('DenseNet 121 using class weights - ROC curve ')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F09p65Et5io"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/My\\ Drive/\n",
        "!touch /content/gdrive/My\\ Drive/my_model_weights.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBfIKPk9t5lZ"
      },
      "outputs": [],
      "source": [
        "def save_model(model, filename):\n",
        "    filepath = '/content/gdrive/My Drive/' + filename\n",
        "    model.save(filepath)\n",
        "\n",
        "save_model(model, 'supervised_learning.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpVQtKSVu_4d"
      },
      "source": [
        "## Unsupervised Learning- Image Segementation\n",
        "\n",
        "- Unsupervised Pneumonia Image Segementation on Chest X-Ray Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZyGQIvRvQaK"
      },
      "outputs": [],
      "source": [
        "# Plot the data\n",
        "f, ax = plt.subplots(2,5, figsize=(40,15))\n",
        "for i in range(10):\n",
        "    img = imread(samples[i])\n",
        "    ax[i//5, i%5].imshow(img, cmap='gray')\n",
        "    if i<5:\n",
        "        ax[i//5, i%5].set_title(\"Normal\")\n",
        "    else:\n",
        "        ax[i//5, i%5].set_title(\"Pneumonia\")\n",
        "    ax[i//5, i%5].axis('off')\n",
        "    ax[i//5, i%5].set_aspect('auto')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YFQjcqBt5oh"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "\n",
        "    # Load the black and white image\n",
        "    img = cv2.imread(samples[i], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Improve image quality\n",
        "    img = cv2.medianBlur(img, 5)\n",
        "\n",
        "    # Apply Canny edge detection on the image\n",
        "    edges = cv2.Canny(img, 100, 200)\n",
        "\n",
        "    # Perform a closing operation on the edges to fill in gaps\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    closed_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Find contours in the image\n",
        "    contours, hierarchy = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create a mask of the same shape as the image\n",
        "    mask = np.zeros_like(img)\n",
        "\n",
        "    # Draw contours on the mask\n",
        "    cv2.drawContours(mask, contours, -1, (255,255,255), -1)\n",
        "\n",
        "    # Apply the mask to the original image\n",
        "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    # Display the original image, edges, and segmented image\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(12, 4))\n",
        "    ax[0].imshow(img, cmap='gray', vmin=img.min(), vmax=img.max())\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[1].imshow(edges, cmap='gray', vmin=edges.min(), vmax=edges.max())\n",
        "    ax[1].set_title('Canny Edges')\n",
        "    ax[2].imshow(closed_edges, cmap='gray', vmin=closed_edges.min(), vmax=closed_edges.max())\n",
        "    ax[2].set_title('Closed Edges')\n",
        "    ax[3].imshow(masked_img, cmap='gray', vmin=masked_img.min(), vmax=masked_img.max())\n",
        "    ax[3].set_title('Segmented Image')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1YQFV-Xt5rZ"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "\n",
        "    # Load the black and white image\n",
        "    img = cv2.imread(samples[i], cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Apply Gaussian blurring to the image\n",
        "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "    # Perform adaptive thresholding on the blurred image\n",
        "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
        "\n",
        "    # Apply Canny edge detection on the thresholded image\n",
        "    edges = cv2.Canny(thresh, 100, 200)\n",
        "\n",
        "    # Apply a dilation operation to the edges to fill in gaps\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    dilated_edges = cv2.dilate(edges,kernel,iterations = 1)\n",
        "\n",
        "    # Apply a closing operation to the dilated edges to remove noise\n",
        "    closing_kernel = np.ones((15,15),np.uint8)\n",
        "    closed_edges = cv2.morphologyEx(dilated_edges, cv2.MORPH_CLOSE, closing_kernel)\n",
        "\n",
        "    # Find contours in the image\n",
        "    contours, hierarchy = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create a mask of the same shape as the image\n",
        "    mask = np.zeros_like(img)\n",
        "\n",
        "    # Draw contours on the mask\n",
        "    cv2.drawContours(mask, contours, -1, (255,255,255), -1)\n",
        "\n",
        "    # Apply the mask to the original image\n",
        "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    # Display the original image, edges, and segmented image\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(12, 4))\n",
        "    ax[0].imshow(img, cmap='gray')\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[1].imshow(thresh, cmap='gray')\n",
        "    ax[1].set_title('Thresholded Image')\n",
        "    ax[2].imshow(edges, cmap='gray')\n",
        "    ax[2].set_title('Canny Edges')\n",
        "    ax[3].imshow(masked_img, cmap='gray')\n",
        "    ax[3].set_title('Segmented Image')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW21p-LCt5uR"
      },
      "outputs": [],
      "source": [
        "def segment_image(img_path):\n",
        "    # Load the black and white image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Apply Gaussian blurring to the image\n",
        "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
        "\n",
        "    # Perform adaptive thresholding on the blurred image\n",
        "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
        "\n",
        "    # Apply Canny edge detection on the thresholded image\n",
        "    edges = cv2.Canny(thresh, 100, 200)\n",
        "\n",
        "    # Apply a dilation operation to the edges to fill in gaps\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    dilated_edges = cv2.dilate(edges,kernel,iterations = 1)\n",
        "\n",
        "    # Apply a closing operation to the dilated edges to remove noise\n",
        "    closing_kernel = np.ones((15,15),np.uint8)\n",
        "    closed_edges = cv2.morphologyEx(dilated_edges, cv2.MORPH_CLOSE, closing_kernel)\n",
        "\n",
        "    # Find contours in the image\n",
        "    contours, hierarchy = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Create a mask of the same shape as the image\n",
        "    mask = np.zeros_like(img)\n",
        "\n",
        "    # Draw contours on the mask\n",
        "    cv2.drawContours(mask, contours, -1, (255,255,255), -1)\n",
        "\n",
        "    # Apply the mask to the original image\n",
        "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    # Display the original image, edges, and segmented image\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(12, 4))\n",
        "    ax[0].imshow(img, cmap='gray')\n",
        "    ax[0].set_title('Original Image')\n",
        "    ax[1].imshow(thresh, cmap='gray')\n",
        "    ax[1].set_title('Thresholded Image')\n",
        "    ax[2].imshow(edges, cmap='gray')\n",
        "    ax[2].set_title('Canny Edges')\n",
        "    ax[3].imshow(masked_img, cmap='gray')\n",
        "    ax[3].set_title('Segmented Image')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPOD9KK0t5xL"
      },
      "outputs": [],
      "source": [
        "new_output = []\n",
        "for image_path in normal_cases[:5]:\n",
        "  output_seg= segment_image(image_path)\n",
        "  new_output.append(output_seg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg57qhsSt5z7"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViQl8871t52z"
      },
      "outputs": [],
      "source": [
        "# define paths to your dataset folders\n",
        "train_data_dir = 'chest_xray/train/'\n",
        "val_data_dir = 'chest_xray/val/'\n",
        "\n",
        "# define image size and batch size\n",
        "img_size = (224, 224)\n",
        "batch_size = 16\n",
        "\n",
        "# define data generators for training and validation\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size=img_size,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(val_data_dir,\n",
        "                                                target_size=img_size,\n",
        "                                                batch_size=batch_size,\n",
        "                                                class_mode='categorical')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESgqg4vwt55s"
      },
      "outputs": [],
      "source": [
        "# build the model\n",
        "model = build_model(input_shape=img_size + (3,))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# define early stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "ckpt_filename= \"/content/drive/MyDrive/unsupervised_learning.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=ckpt_filename, save_best_only=True, save_weights_only=True, verbose = 1)\n",
        "\n",
        "# train the model using the generators\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=len(train_generator),\n",
        "                    epochs=20,\n",
        "                    validation_data=val_generator,\n",
        "                    validation_steps=len(val_generator),\n",
        "                    callbacks=[early_stop])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tZ48hJ0t58k"
      },
      "outputs": [],
      "source": [
        "# plot the training and validation accuracy and loss\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(history.history['accuracy']))\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sseYvnft5_p"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/gdrive/My\\ Drive/\n",
        "!touch /content/gdrive/My\\ Drive/my_model_weights.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jj1jUcQft6Cb"
      },
      "outputs": [],
      "source": [
        "def save_model(model, filename):\n",
        "    filepath = '/content/gdrive/My Drive/' + filename\n",
        "    model.save(filepath)\n",
        "\n",
        "save_model(model, 'Unsupervised_learning.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4coHAeoUvsWq"
      },
      "source": [
        "## Multitask Learning\n",
        "\n",
        "- Addition of Supervised & Unsupervised learning losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsoyA0xjvfcO"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained classification and segmentation models\n",
        "classification_model = tf.keras.models.load_model('/content/gdrive/My Drive/supervised_learning.h5')\n",
        "segmentation_model = tf.keras.models.load_model('/content/gdrive/My Drive/Unsupervised_learning.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQnA4Qawt6FY"
      },
      "outputs": [],
      "source": [
        "# Remove the last layer of the classification model\n",
        "classification_model.layers.pop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO6WJlnqt6Id"
      },
      "outputs": [],
      "source": [
        "# Add a shared multi-task layer to the segmentation model\n",
        "shared_layer = Dense(256, activation='relu')(segmentation_model.layers[-2].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMv1UkVQt6Ly"
      },
      "outputs": [],
      "source": [
        "# Combine the modified classification model and segmentation model into a single model\n",
        "classification_output = classification_model.layers[-1].output\n",
        "multi_task_output = concatenate([shared_layer, classification_output])\n",
        "multi_task_model = tf.keras.Model(inputs=[classification_model.input, segmentation_model.input], outputs=[multi_task_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZxbbIjrt6OO"
      },
      "outputs": [],
      "source": [
        "# Define the loss function for the combined model to include both classification and segmentation losses\n",
        "classification_loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "segmentation_loss = tf.keras.losses.BinaryCrossentropy()\n",
        "losses = {\n",
        "    'classification': classification_loss,\n",
        "    'segmentation': segmentation_loss\n",
        "}\n",
        "loss_weights = {\n",
        "    'classification': 1.0,\n",
        "    'segmentation': 0.5\n",
        "}\n",
        "multi_task_model.compile(optimizer='adam', loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UYfUbPHt6Qm"
      },
      "outputs": [],
      "source": [
        "multi_task_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LOI3vost6Th"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant',\n",
        "    validation_split=0.1,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSPndP96t6Wq"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant',\n",
        "    validation_split=0.1,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "image_size = 224\n",
        "batch_size = 16\n",
        "\n",
        "train_classification_gen = train_datagen.flow_from_directory(\n",
        "    train_dir_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='training',\n",
        "    color_mode='grayscale' # specify grayscale color mode\n",
        ")\n",
        "\n",
        "train_segmentation_gen = train_datagen.flow_from_directory(\n",
        "    train_dir_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True,\n",
        "    subset='training',\n",
        "    color_mode='grayscale' # specify grayscale color mode\n",
        ")\n",
        "\n",
        "val_classification_gen = train_datagen.flow_from_directory(\n",
        "    train_dir_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    subset='validation',\n",
        "    color_mode='grayscale' # specify grayscale color mode\n",
        ")\n",
        "\n",
        "val_segmentation_gen = train_datagen.flow_from_directory(\n",
        "    train_dir_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True,\n",
        "    subset='validation',\n",
        "    color_mode='grayscale' # specify grayscale color mode\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True,\n",
        "    color_mode='grayscale' # specify grayscale color mode\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxPtBF6Rt6hi"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: zip(train_classification_gen, train_segmentation_gen),\n",
        "    output_types=((tf.float32, tf.float32), (tf.float32,)),\n",
        "    output_shapes=(((batch_size, image_size, image_size, 1), (batch_size, image_size, image_size, 1)), (batch_size,)),\n",
        ")\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: zip(val_classification_gen, val_segmentation_gen),\n",
        "    output_types=((tf.float32, tf.float32), (tf.float32,)),\n",
        "    output_shapes=(((batch_size, image_size, image_size, 1), (batch_size, image_size, image_size, 1)), (batch_size,)),\n",
        ")\n",
        "\n",
        "multi_task_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=20,\n",
        "    validation_data=val_dataset\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}